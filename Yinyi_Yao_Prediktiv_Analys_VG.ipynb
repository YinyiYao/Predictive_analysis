{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Set Information:\n",
    "\n",
    "**A dataset containing the targets and 24 features of 2930 individual objects(rows).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing useful libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing data\n",
    "predictive = pd.read_csv('prediktiv_data.csv',index_col='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers and NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of NaN values\n",
    "nan_per_col =predictive.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing all variables with missing values\n",
    "missing_values = nan_per_col[nan_per_col>0]\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting columns with majority of missing values\n",
    "predictive.drop(['feature11','feature12','feature15'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical, use most frequent\n",
    "print(predictive['feature13'].value_counts())\n",
    "predictive['feature13'].fillna('red', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical, use most frequent\n",
    "print(predictive['feature01'].value_counts())\n",
    "predictive['feature01'].fillna(2, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictive.boxplot('feature02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature02 has many outliers, NaN are replaced by median\n",
    "imputer =SimpleImputer(strategy='median', missing_values=np.nan)\n",
    "imputer = imputer.fit(predictive[['feature02']]) \n",
    "predictive['feature02'] = imputer.transform(predictive[['feature02']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictive.boxplot('feature04')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature04 has many outliers, NaN are replaced by median\n",
    "imputer =SimpleImputer(strategy='median', missing_values=np.nan)\n",
    "imputer = imputer.fit(predictive[['feature04']]) \n",
    "predictive['feature04'] = imputer.transform(predictive[['feature04']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One of the transformations we must perform is to tranform the categorical features to the dummy-variable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables\n",
    "predictive=pd.concat([predictive,pd.get_dummies(predictive['feature13'],prefix='feature13',drop_first=True)],axis=1)\n",
    "predictive=pd.concat([predictive,pd.get_dummies(predictive['feature16'],prefix='feature16',drop_first=True)],axis=1)\n",
    "predictive.drop(['feature13','feature16'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing the distribution of target.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.title('Target Distribution Plot')\n",
    "sns.histplot(predictive['target'],kde=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Square root transformation is used to normalize our target variable\n",
    "predictive['target'] = np.sqrt(predictive['target'])\n",
    "sns.histplot(predictive['target'],kde=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictive.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Many variables have a skewed distribution according to histplot above, the dataset provides a good candidate for using a robust scaler transform to standardize the data in the presence of skewed distributions and outliers. (only continuously input variables can be preprocessed by robust scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using all the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into: trainning and testing (cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_name = 'target'\n",
    "robust_scaler=RobustScaler()\n",
    "x =predictive.drop('target', axis=1)\n",
    "feature_names=x.columns\n",
    "x=robust_scaler.fit_transform(x)\n",
    "y = predictive[target_name]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import the estimator object (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create an instance of the estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linear_regression = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Use the trainning data to train the estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred_test = linear_regression.predict(x_test)\n",
    "error_metric = mean_squared_error(y_pred=y_pred_test, y_true=y_test)\n",
    "print('The Mean Square Error of this model is: ', error_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print coefficients and intercept for the multiple regression model\n",
    "inter = linear_regression.intercept_\n",
    "weights = linear_regression.coef_\n",
    "print(f'The intercept of the trained model is {inter} and the weights are {weights}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_test, y_pred_test,s=4)\n",
    "ax.plot(y_test, y_test, color='red')\n",
    "ax.set_xlabel('Testing target values')\n",
    "ax.set_ylabel('Predicted target values')\n",
    "ax.set_title('Predicted vs. Actual values');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a plot of the true target *y_true* plotted against the predicted target, *y_pred*. Note that the red line is not the one-dimensional plot of the linear regression. It is the true y plotted against itself. This will always create a 45 degree straight line. We want all the scatter plots to be as close to this line as possible because this means y_pred = y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making predictions with the most relevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose 20 features which have the highest correlation with the target\n",
    "top_corr_features = predictive.corr().loc['target'].apply(np.abs).sort_values(ascending=False).index[1:21]\n",
    "top_corr_features = list(top_corr_features)\n",
    "top_corr_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check multicollinearity between these chosen features\n",
    "plt.figure(figsize = (20, 20))\n",
    "sns.heatmap(predictive[top_corr_features].corr(), cmap=\"RdYlGn\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the train and test sets and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = predictive[top_corr_features]\n",
    "target_name = 'target'\n",
    "y = predictive[target_name]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing a DataFrame for model analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mean = pd.DataFrame(index=['MSE', 'RMSE', 'MAE'], \n",
    "columns=['NULL', 'MLR','KNN','LASSO','RandomForest'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making predictions with just a few features (top 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Null model: always predict the average of the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "y_pred_null = y_train.mean()\n",
    "model_mean.loc['MSE','NULL'] = mean_squared_error(y_pred=np.repeat(y_pred_null, y_test.size), y_true=y_test)\n",
    "model_mean.loc['RMSE','NULL'] = mean_squared_error(y_pred=np.repeat(y_pred_null, y_test.size), y_true=y_test, squared=False)\n",
    "model_mean.loc['MAE','NULL'] = mean_absolute_error(y_pred=np.repeat(y_pred_null, y_test.size), y_true=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. Import the estimator object (model)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# 2. Create an instance of the estimator\n",
    "linear_regression = LinearRegression()\n",
    "# 3. Use the training data to train the estimator\n",
    "linear_regression.fit(x_train, y_train)\n",
    "# 4. Evaluate the model\n",
    "model_mean.loc['MSE','MLR'] = mean_squared_error(y_pred=linear_regression.predict(x_test), y_true=y_test)\n",
    "model_mean.loc['RMSE','MLR'] = mean_squared_error(y_pred=linear_regression.predict(x_test), y_true=y_test, squared=False)\n",
    "model_mean.loc['MAE','MLR'] = mean_absolute_error(y_pred=linear_regression.predict(x_test), y_true=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. K-Nearest Neighbors Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. Import the estimator object (model)\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# 2. Create an instance of the estimator\n",
    "knn = KNeighborsRegressor(n_neighbors=10, weights='distance', metric='euclidean', n_jobs=-1)\n",
    "# 3. Use the trainning data to train the estimator\n",
    "knn.fit(x_train, y_train)\n",
    "# 4. Evaluate the model\n",
    "model_mean.loc['MSE','KNN'] = mean_squared_error(y_pred=knn.predict(x_test), y_true=y_test)\n",
    "model_mean.loc['RMSE','KNN'] = mean_squared_error(y_pred=knn.predict(x_test), y_true=y_test, squared=False)\n",
    "model_mean.loc['MAE','KNN'] = mean_absolute_error(y_pred=knn.predict(x_test), y_true=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "# 2. Create an instance of the estimator\n",
    "lasso = Lasso(alpha=0.05)                            \n",
    "# 3. Use the training data to train the estimator\n",
    "lasso.fit(x_train, y_train)\n",
    "# 4. Evaluate the model\n",
    "model_mean.loc['MSE','LASSO'] = mean_squared_error(y_pred=lasso.predict(x_test), y_true=y_test)\n",
    "model_mean.loc['RMSE','LASSO'] = mean_squared_error(y_pred=lasso.predict(x_test), y_true=y_test, squared=False)\n",
    "model_mean.loc['MAE','LASSO'] = mean_absolute_error(y_pred=lasso.predict(x_test), y_true=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# 2. Create an instance of the estimator\n",
    "RF = RandomForestRegressor(n_estimators=50, max_depth=20,random_state=40, n_jobs=-1)\n",
    "# 3. Use the training data to train the estimator\n",
    "RF.fit(x_train, y_train)\n",
    "# 4. Evaluate the model\n",
    "model_mean.loc['MSE','RandomForest'] = mean_squared_error(y_pred=RF.predict(x_test), y_true=y_test)\n",
    "model_mean.loc['RMSE','RandomForest'] = mean_squared_error(y_pred=RF.predict(x_test), y_true=y_test, squared=False)\n",
    "model_mean.loc['MAE','RandomForest'] = mean_absolute_error(y_pred=RF.predict(x_test), y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "model_mean.T.plot(kind='barh', ax=ax)\n",
    "ax.set_title('MSE for Regression Models')\n",
    "ax.legend(loc=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "model_mean.loc['MSE'].plot(kind='barh', ax=ax)\n",
    "ax.set_title('Test MSE for Regression Models')\n",
    "ax.legend(loc=8, ncol=4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Features automatically choosen by Lasso:\\n')\n",
    "for i,var in enumerate(x.columns[lasso.coef_>0]):\n",
    "    print(\"{}.{}\".format(i+1, var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use best model LASSO to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.scatter(lasso.predict(x_test), y_test, s=4)\n",
    "ax.plot(y_test, y_test, color='red')\n",
    "ax.set_title('LASSO: predictions vs. observed values (test data)')\n",
    "ax.set_xlabel('Predicted target')\n",
    "ax.set_ylabel('Testing target');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
